KRISHNA BEZAWADA
Lead Full Stack Data Scientist with AI / ML | MLOps Engineer (9+ Years)
+1-737-295-8444	aikrishna24@gmail.com	LinkedIn(click on me)


 Professional Summary	

•	I have 9+ years of experience (7+ completely in AI/ML), built End-End AI/ML solutions for clients in Insurance, Healthcare, Entertainment, Banking, Construction, Manufacturing industries.
•	Started my career as a Front-end Developer and was eventually promoted to Junior Data Scientist with a focus on Machine Learning. This was a kickstarter in AI/ML domain for me, and for the last 2 years in Generative AI (LLMs such as GPT, BERT, Roberta, DistilBERT, Text-Text).
•	I also run my own start-up company in INDIA for almost 15 months during covid time we’ve provided AI
based automated digital services to our clients in Construction C Healthcare.
•	Good experience in data collection, data generation, data cleansing, building ML models (batch and real-time), deploying models, and showcasing results to client.
•	Been using Data Science Python Libraries (Pandas, NumPy, Keras, Scikit-Learn) C frameworks like PyTorch, TensorFlow.
•	Productionized RAG based solution in AWS using S3, Athena, SageMaker, Lambda, Bedrock (LLAMA, Claude, Titan), Azure and GCP.
•	Using Machine Learning (Supervised, Unsupervised, Reinforcement), Deep Learning (CNN, RNN, ANN) built many models and containerized using Docker for EC2, Kubernetes.
•	Built models in VS Code, Jupyter Notebook, SageMaker, Vertex AI, Azure ML.
•	Used GitHub as repository, GitHub actions.
•	Built CI/CD pipelines during production to monitor ML models.
•	Familiar with AIOps, MLOps standard practices.
•	Used project management tools Jira and Asana.
•	Built visualizations using Dash, Power BI, Seaborn, MatPlot, Angular, React JS, Bootstrap, HTML, CSS3.

	Other Skills & Tools	
•	Data Science Skills: Data Mining, Data Visualization, Data Analysing, Snowflake, Data Wrangling, Data Warehousing, Probability C Statistics, Web Scrapping, Spark, Python, Hadoop, Apache, Hive.
•	Databases: MongoDB, SQL, Chroma DB (Vector DB).
•	Front End: Angular, PHP, jQuery, JavaScript, Bootstrap, CSS3, HTML5.
•	Cloud: GCP, Azure, AWS, Databricks.
•	Visualization Tools: Power BI.


	Educational Background	

•	University of Central Missouri – Warrensburg, MO - USA.
o	Master’s in computer science – Graduated in Dec 2022.
•	KL University – Guntur, AP - INDIA.
o	Bachelor of Technology in Electronics C Computer Science Engineering – Graduated in May 2017.
 
	Professional Summary	



Lead for Sentiment Analysis C senior resource for 3D CAD encap parts generation using Generative AI are major projects. I’ve built data collection program using Selenium + Python, this is deployed using AWS ECS. Responsibilities:
	For 3D image generation, we need to do Part Similarity search for this I have implemented K-NN model.
	Loaded document, images data into Aurora DB using AWS Textract (OCR tool).
	Created ETL pipeline in Databricks for image generation project.
	Built web scraping python and selenium program and deployed as container in AWS EC2.
	Used Logistic Regression, Naïve Bayes, XG-Boost, Decision Tree in sentiment analysis.
	Deployed ML models Docker images in AWS ECS to make end-points available for Generative AI models.
	Analyzed time series lab data using PySpark and Pandas.
	Converted text into numerical features using techniques like Bag of Words, TF-IDF, Word2Vec.
	Tested Vector Index methods on Chroma DB, used LLM (Palm) for querying on Aurora DB.
	Stored embeddings generated by Titan into Chroma Vector database, indexed by OpenSearch.
	Built RAG based solution in AWS, deployed to whole company AWS network as an internal use-case using Bedrock (LLMs such as GPT3.5, GPT4, Claude, LLAMA, Titan), S3, Lambda, SageMaker, Beanstalk.
	Built Python functions in Lambda for Sentiment analysis.
	Built UI for conversations over RAG system using React JS.
Environment:
	Python (PyTorch, TensorFlow, Keras, OpenCV, NumPy, SciPy, Typescript, Pandas, Scikit-learn, seaborn) , GitHub, RAG, GPT3.5, GPT4, MySQL, and Spark 2.0 (PySpark), AWS, GCP, Databricks, OpenSearch , React JS, Vector Database, Bedrock.



Client is in entertainment industry, using Artificial Intelligence we’re generating images and customer support chatbot using LangChain, React JS are major projects.
Responsibilities:
	Deployed AI, Machine learning and Deep Learning models, Transformers built using TensorFlow, OpenCV, Keras on to Azure Data Factory and automated the CI / CD pipelines to monitor KPIs.
	Used the power of Azure ML, and during POC we’ve used Google Vertex AI, Auto-ML, and AWS SageMaker as well with React JS as User Interface.
	Used LSTM, Bi-LSTM for larger sentences analysis.
	Used Traditional models such as Naïve Bayes, XG-Boost, Logistic regression for chatbot project.
 
	Streamlined structured data in real time via batch mode using Apace KAFKA from HDInsight.
	Extracted characters in images using OCR techniques, and object detection using Yolo.
	Tested Databricks for Chatbot project during POC. But, used Azure cloud in production.
	Data generation for chatbot using Snowflake performed ETL, NLP tasks.
	Data pre-processing using Google Big Query for Image generation and loaded using Spark (PySpark) with Hadoop techniques, and financial data into SQL server using SQL SSIS.
	Built REST API using Flask for front-end built in React JS.
Environment:
	Python (PyTorch, TensorFlow, Keras, OpenCV, NumPy, GitHub, Typescript, SciPy, Computer Vision, Django, pandas, Scikit-learn, seaborn, Matplotlib), R, Looker, Databricks, MATLAB, R, MySQL, Snowflake, GCP, GPT3, Gpt3.5, Dataiku, GRPC, and Spark 2.0 (PySpark), Azure, AWS.



Client is in Health Care, we built automated models to predict chances of diabetes and suggested diet based on predictions.
Responsibilities:
	Used Python libraries such as Pandas, NumPy, Scikit-Learn.
	Built various statistical techniques to manipulate the data (missing data imputation, principal component analysis and sampling).
	Worked on AWS S3, Glue, Athena, Lambda, SageMaker for data processing of customers fitness data.
	Synthetic data generation using Neural Networks to detect potential chances for lung diseases.
	Extracted contents from images using OCR techniques.
	Built Regression models (Linear regression) for diabetes prediction and Classification models (K-NN) for diet suggestions in ADF by tuning Hyperparameters for more accuracy.
	Deployed DL models (TensorFlow, PyTorch, OpenCV, Keras) using containers built using Docker on to Azure Data Factory and GCP Vertex AI to perform performance analysis. Performed A/B testing during models development phase.
	Automated the pipelines on Azure DevOps C published the KPI onto user device app through APIs.
	Used real-time algorithms connected to User device sensors using Azure ML APIs.
	Worked on latest papers published by PhD students for fast C more accurate results.
	Done research on OpenAI APIs to integrate in project.
Environment:
	Python 3.X C libraries, GitHub, AWS, Azure, Docker, Typescript , Classification, Regression ML models, GCP, Azure, NLP, Tableau, R, MySQL, Spark.
 
 
Used various frontend and backend technologies to develop and deploy dynamic UI layouts for all types of mailing servers over an Artificial Intelligence based platform.

Responsibilities:
	Leveraged C improved Litmus AI based platform performance using statistical techniques.
	Developed dynamic user interface using HTML, CSS, JavaScript, and other web technologies techniques.
	Deploy media over in-house VPC like platform and used the sources to link in development.
	Deployed developed modules in litmus an AI based software to perform testing over 100+ mailing servers.
	Built AWS SageMaker end points for campaign KPI monitoring on Beanstalk application.
	Worked with AWS Beanstalk to send automatic emails for client’s customers upon event-based triggering.
	Triggers emails to clients as per schedule / manual process.
	Maintained daily tasks in Jira C worked on Agile methodology.
Environment:
	HTML5, CSS3, Jira, JavaScript, Litmus, Typescript, AWS, SageMaker.


Developed AI based application for hospitals to manage their daily functionalities and some other applications using AI.

Responsibilities:
	This is my own startup company, started just 3 months back to COVID-19, got opportunity to build technology for patients suffering with the new virus.
	Built a website to make awareness of COVID-19 using Python, Flask, SQL deployed on GoDaddy hosting server.
	This website has been integrated with real-time data from Google, MIT to reduce the fear of COVID- 19.
	Built a Speech recognition system to answer patients queries, data collected from experienced scientists C doctors.
	Implemented cutting-edge ML techniques to build scientific reports to enhance their business C identify the potential drawback areas that they are lagging. Used Decision Trees, Forecasting, Classification, Clustering, Regression with Supervised, Unsupervised and Reinforcement techniques.
	Collected data collection in text and CSV format, SQL databases and analyze both structured and unstructured data using various algorithms to discover trends and applied Pandas to do pre- processing.
	Analyzed character extraction from images of hospital patients applications using OpenCV, TensorFlow.
	Used Hugging Face libraries for NLP methods to understand the context of sentences.
 
	Built models using neural networks with models YOLO on CV technology for character recognition, image recognition.
	After A/B testing we’ve deployed models in different cloud servers; GCP, Azure, AWS SageMaker for
faster response using real-time models. Built docker containers for EC2 instance.
	Built reports for clients using python libraries such as seaborn, matplotlib, gg-plot.
Environment:
	Python, R, SQL, OpenCV, PyTorch, Pandas, NumPy, TensorFlow, Docker, Keras, Matplotlib, Seaborn, GCP, AWS, Azure, Supervised, Unsupervised, Reinforcement Learning, Regression ML models, Hugging Face.




A startup-based company based in Hyderabad major area of operation is Insurance. Used Python C various ML techniques collected data, preprocess and analyzing to build predictive models that are helpful for the company financial decisions.

Responsibilities:
	We've collected the data from their existing SQL C No-SQL databases, then we've stored that into our in-house platform SQL server.
	Analyze the data using various data science methods with the help of Python C it’s libraries.
	Worked on Feature engineering techniques such as one hot encoding to assign numerical values for every distinct data in columns, hashing for temporary storage.
	Utilized Classification, Regression algorithms to predict insurance sales and understand the users who are likely to buy an insurance.
	Productionized models onto AWS platform using Docker containers.
	During the first year, I have developed static and dynamic web applications for clients using Angular, Bootstrap, HTML, JavaScript, NodeJS, SQL.
	Deployed them on in-house, cloud servers.
	Developed screen based responsive application using full-stack technologies such as Python, Django, Flask, Php, Angular, Node, SQL, JavaScript, and other web technologies.
Environment:
	Python, NumPy, TensorFlow, Seaborn, Matplotlib, Pandas, AWS, ML algorithms, Angular, Node JS, VS Code, GCP.



A startup-based company based in Vijayawada major area of operation is web app development. Used various web technologies such as Php, HTML5, Bootstrap, CSS3, JavaScript.

Responsibilities:
	This is a part of academics.
	Deployed UI components for our clients.
	Learned and implemented Php, SQL, JavaScript, and other web technologies.
Environment:
	Web Technologies, AWS, VS Code, Php.
 
 
A startup Hub started in Vijayawada during our academic summer break to provide websites for businesses in our region. Built using HTML, CSS, Bootstrap, and JavaScript. Deployed into shared hosting.

Responsibilities:
	Deployed on HostingRaja, Godaddy shared servers.
	Websites maintained.
Environment:
	Web Technologies, VS Code.



Intern as UI developer during summer – 1 as a part of academics.

Responsibilities:
	Build static and dynamic websites using HTML, CSS, JavaScript in Dreamweaver.
	Deployed on college servers.
Environment:
	HTML, CSS, JavaScript, Server, Dreamweaver.


[KRISHNA B]
